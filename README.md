# ğŸµ MusicAbility â€” Foundry + Speech

**UCENFOTEC Â· Aplicaciones de IA Â· Cuatrimestre 4**

---

## DescripciÃ³n

MusicAbility es una aplicaciÃ³n web de **accesibilidad musical** construida con Streamlit. Permite a cualquier usuario describir una idea musical â€”escribiendo texto o hablando por micrÃ³fonoâ€” y obtener automÃ¡ticamente un archivo MIDI listo para descargar.

La app utiliza **Azure AI Foundry** (modelo `gpt-5-nano`) para interpretar la descripciÃ³n y generar la estructura musical, y **Azure Speech-to-Text** para transcribir instrucciones de voz.

---

## Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Navegador (Streamlit)                  â”‚
â”‚                                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ âœï¸ Texto      â”‚          â”‚ ğŸ™ï¸ MicrÃ³fono         â”‚     â”‚
â”‚   â”‚ (text_area)  â”‚          â”‚ (audio_recorder)     â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚          â”‚                             â”‚                 â”‚
â”‚          â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚          â”‚                    â”‚ Azure Speech    â”‚        â”‚
â”‚          â”‚                    â”‚ (STT REST API)  â”‚        â”‚
â”‚          â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚          â”‚                             â”‚ texto           â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                     â–¼                                    â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚          â”‚ Azure AI Foundry    â”‚                         â”‚
â”‚          â”‚ (gpt-5-nano)        â”‚                         â”‚
â”‚          â”‚ prompt â†’ JSON       â”‚                         â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                   â–¼                                      â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚          â”‚ Generador MIDI      â”‚                         â”‚
â”‚          â”‚ (Python puro)       â”‚                         â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                   â–¼                                      â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚          â”‚ ğŸ’¾ Descarga .mid    â”‚                         â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo paso a paso

1. **Entrada** â€” El usuario elige una de dos pestaÃ±as:
   - **Escribir texto**: escribe la instrucciÃ³n musical en un campo de texto.
   - **Grabar con micrÃ³fono**: graba audio desde el navegador; la grabaciÃ³n se envÃ­a a **Azure Speech-to-Text** (REST API, regiÃ³n `southcentralus`, idioma `es-CR`) y se muestra el texto reconocido.
2. **GeneraciÃ³n del JSON musical** â€” El texto (escrito o transcrito) se envÃ­a a **Azure AI Foundry** (chat completions, modelo `gpt-5-nano`). Un *system prompt* detallado obliga al modelo a devolver un JSON con: `title`, `tempo_bpm`, `key`, `length_bars`, `time_signature`, `melody[]` y `assumptions[]`.
3. **ConstrucciÃ³n del MIDI** â€” El JSON se procesa con un generador MIDI escrito en Python puro (sin dependencias externas). Se construye un archivo MIDI tipo 0, 480 ticks/beat, canal 0, programa 0 (piano). Las notas se limitan al rango C3â€“C5.
4. **VisualizaciÃ³n y descarga** â€” La app muestra mÃ©tricas (tonalidad, tempo, compases), una tabla de notas, el JSON completo, y un botÃ³n de descarga del archivo `.mid`.

---

## Estructura del proyecto

```
musicability-foundry-speech/
â”œâ”€â”€ app.py              # AplicaciÃ³n principal (Streamlit)
â”œâ”€â”€ .env                # Variables de entorno (no se sube al repo)
â”œâ”€â”€ requirements.txt    # Dependencias de Python
â”œâ”€â”€ instrucciones/      # DocumentaciÃ³n interna del proyecto
â””â”€â”€ README.md           # Este archivo
```

---

## Requisitos previos

- **Python 3.11+**
- Una suscripciÃ³n a Azure con:
  - **Azure AI Foundry** (endpoint + API key + deployment de `gpt-5-nano`)
  - **Azure Speech Service** (clave + regiÃ³n)

---

## InstalaciÃ³n

```bash
# 1. Clonar el repositorio
git clone <url-del-repo>
cd musicability-foundry-speech

# 2. Crear y activar entorno virtual
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS / Linux
source .venv/bin/activate

# 3. Instalar dependencias
pip install -r requirements.txt
```

---

## ConfiguraciÃ³n

Crear un archivo `.env` en la raÃ­z del proyecto con las siguientes variables:

```env
# Azure Speech (Speech-to-Text)
SPEECH_KEY=<tu-clave-de-speech>
SPEECH_ENDPOINT=https://<region>.stt.speech.microsoft.com
AZURE_SPEECH_REGION="<region>"

# Azure AI Foundry (Chat Completions)
FOUNDRY_API_KEY=<tu-api-key>
FOUNDRY_ENDPOINT=https://<recurso>.services.ai.azure.com/api/projects/<proyecto>
MODEL_DEPLOYMENT_NAME=<nombre-del-deployment>
MODEL_NAME=gpt-5-nano
```

---

## EjecuciÃ³n

```bash
streamlit run app.py
```

La app se abrirÃ¡ en el navegador (por defecto `http://localhost:8501`).

---

## Uso

### OpciÃ³n 1 â€” Escribir texto

1. Abre la pestaÃ±a **"âœï¸ Escribir texto"**.
2. Escribe una instrucciÃ³n, por ejemplo: *"Una melodÃ­a alegre en Sol mayor, 4 compases, tempo rÃ¡pido"*.
3. Presiona **"ğŸ¼ Generar melodÃ­a"**.
4. Espera unos segundos mientras el modelo genera el JSON y se construye el MIDI.
5. Descarga el archivo `.mid`.

### OpciÃ³n 2 â€” Grabar con micrÃ³fono

1. Abre la pestaÃ±a **"ğŸ™ï¸ Grabar con micrÃ³fono"**.
2. Presiona el botÃ³n del micrÃ³fono y dicta tu instrucciÃ³n musical.
3. Presiona de nuevo para detener la grabaciÃ³n.
4. La app transcribe el audio automÃ¡ticamente y muestra el texto reconocido.
5. Presiona **"ğŸ¼ Generar melodÃ­a desde voz"**.
6. Descarga el archivo `.mid`.

---

## Dependencias

| Paquete                    | PropÃ³sito                                      |
| -------------------------- | ---------------------------------------------- |
| `streamlit`                | Framework de la interfaz web                   |
| `python-dotenv`            | Carga de variables de entorno desde `.env`     |
| `requests`                 | Llamadas HTTP a Azure AI Foundry y Speech API  |
| `audio-recorder-streamlit` | Componente de grabaciÃ³n de audio en el browser |

---

## Servicios de Azure utilizados

| Servicio               | Uso en la app                                                |
| ---------------------- | ------------------------------------------------------------ |
| **Azure AI Foundry**   | GeneraciÃ³n del JSON musical a partir de texto (gpt-5-nano)  |
| **Azure Speech (STT)** | TranscripciÃ³n de voz a texto para la entrada por micrÃ³fono   |

---
